### Verifying NGINX Ingress Installation and Understanding Google Cloud Load Balancer Integration

#### 1. Verifying Workloads in Kubernetes Console

* After installing **Ingress-NGINX** with Helm, refresh the Google Cloud Kubernetes Console.
* Navigate to **Workloads**.
* You should now see:

  * **Ingress Controller** — the deployment managing the NGINX Ingress controller pod that reads the Ingress configuration and configures NGINX routing.
  * **Ingress Default Backend** — provides default health checks and a fallback 404 page for undefined routes.

> The default backend is automatically created. It’s acceptable to use this instead of a custom health check route for now.

---

#### 2. Checking Services

* Go to the **Services** tab in the console.
* Look for a service of type **LoadBalancer**.

  * It should display **two sets of IP addresses** — external and internal.
* If these IPs haven’t appeared yet, wait a few minutes and refresh the page.

When both IPs are visible:

* Click on the **External IP** with port `:80`.
* A new tab will open showing a **“default backend – 404”** message.

  * This confirms that the LoadBalancer and default backend are working correctly.

---

#### 3. Viewing the Google Cloud Load Balancer

* Open the **Navigation menu → Networking → Network Services → Load Balancing**.
* This page shows the **Google Cloud Load Balancer** automatically created by Kubernetes during the Helm installation.

Details:

* The Load Balancer’s external IP matches the one used to access `:80`.
* It routes incoming traffic to a group of instances — representing the three Kubernetes nodes in the cluster.

---

#### 4. Ingress–Load Balancer Flow

Traffic flow summary:

1. **Client → Google Cloud Load Balancer** (external entry point)
2. **Load Balancer → Kubernetes LoadBalancer Service** (Kubernetes-managed)
3. **Service → NGINX Ingress Controller Pod**
4. **Ingress Controller → Target Deployments/Services** based on Ingress rules

This setup bridges external traffic from Google Cloud networking into internal Kubernetes routing.

---

#### 5. Next Step

The infrastructure is now complete:

* Kubernetes cluster
* NGINX Ingress controller
* Google Cloud Load Balancer

Next, deploy the actual application workloads into the cluster.
