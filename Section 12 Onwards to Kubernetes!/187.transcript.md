### Kubernetes Architecture — Internal Workflow (Tutor Notes)

#### 1. Overview

* The previous section demonstrated Kubernetes activity within a local node.
* The focus now shifts to understanding what happens internally when a configuration file is fed into `kubectl apply`.
* Example: Deployment of a pod using configuration files for a client and service.

---

#### 2. Initial Demonstration (Behavior of Pods and Containers)

* Command: `kubectl get pods`

  * Displays pod status: **0 restarts**, **1-hour age**.
* Run `docker ps`

  * Lists multiple containers including `multi-client`.
  * This container is part of the running pod.
* Run `docker kill <container_id>`

  * Terminates the container within the pod.
* Run `docker ps` again

  * Container reappears — recreated **2 seconds ago**.
* Run `kubectl get pods` again

  * Shows **1 restart**.

**Conclusion:**
If a container inside a pod crashes or is manually deleted, Kubernetes automatically restarts it. This behavior reflects Kubernetes’ self-healing mechanism.

---

#### 3. Core Kubernetes Components (High-Level Architecture)

* **Master Node** — Controls and manages the cluster.

  * Runs multiple programs (focus: **Kube API Server**).
  * Monitors node states and ensures cluster conformity.
  * Maintains a **list of responsibilities** — tasks derived from deployment configurations.
* **Worker Nodes** — Physical or virtual machines running pods.

  * Each node includes a **Docker engine** (or container runtime).
  * Responsible for pulling images and running containers.
* **Docker Hub** — Repository for pulling images.

---

#### 4. Step-by-Step Flow: What Happens When You Run `kubectl apply`

1. Developer executes:

   ```bash
   kubectl apply -f deployment.yaml
   ```

   Example: Deployment file requests **4 replicas** of the `multi-worker` image.
2. The command sends the configuration to the **Kube API Server** (master).
3. The master interprets the file and updates its internal record:

   ```
   Desired state: 4 replicas of multi-worker
   Current state: 0 replicas
   ```
4. The master instructs the worker nodes to start containers:

   * Node 1 → 2 copies of `multi-worker`
   * Node 2 → 1 copy
   * Node 3 → 1 copy
5. Each node’s **Docker runtime** pulls `multi-worker` from **Docker Hub** and caches it locally.
6. Containers are created accordingly:

   * Node 1: 2 containers
   * Node 2: 1 container
   * Node 3: 1 container
7. The master queries each node for status:

   * Node 1: running 2
   * Node 2: running 1
   * Node 3: running 1
   * Total: 4 replicas running.
8. Master updates its state to reflect synchronization:

   ```
   Desired state: 4 replicas
   Current state: 4 replicas
   ```

   System reaches equilibrium.

---

#### 5. Continuous Monitoring and Recovery

* The master **continuously polls** all nodes.
* If a container crashes (e.g., after `docker kill`):

  1. Master detects the failure.
  2. Updates its internal record: “Only 3 replicas active.”
  3. Instructs a node (e.g., Node 3) to create a new container.
  4. Node uses the cached image to recreate the container.
  5. Master confirms the count: 4 replicas running again.

**Result:** Kubernetes restores the desired state automatically.

---

#### 6. Key Takeaways

* Developers **never interact directly with worker nodes**.

  * All commands go through **`kubectl` → Kube API Server → Master → Worker nodes**.
* The **master node manages state consistency** across the cluster.

  * Constantly ensures that the **actual state matches the desired state** from deployment files.
* This mechanism is the foundation of Kubernetes’ **self-healing and declarative architecture**.
* The master continually reconciles its **list of responsibilities** until the cluster matches the specified configuration.

---

#### 7. Next Step

The next section expands on how developers interact with Kubernetes, focusing on the master’s responsibility list and how it enforces desired state management across the cluster.
